{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T18:35:30.271188Z",
     "iopub.status.busy": "2021-03-14T18:35:30.250294Z",
     "iopub.status.idle": "2021-03-14T18:44:33.662919Z",
     "shell.execute_reply": "2021-03-14T18:44:33.661788Z"
    },
    "papermill": {
     "duration": 543.420159,
     "end_time": "2021-03-14T18:44:33.663156",
     "exception": false,
     "start_time": "2021-03-14T18:35:30.242997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37a9489bb4b4cce9c8162dc961dbe21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.010000\n",
      "Learning rate: 0.001000\n",
      "Start accuracy tests\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "Validation accuracy: 0.748574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.010000\n",
      "Learning rate: 0.001000\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "EPOCHS = 7\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 224\n",
    "K_FOLDS = 5\n",
    "VALIDATION_PERC = 0.2\n",
    "TRAIN_DATA_PATH = '../input/birds21wi/birds/train'\n",
    "TEST_DATA_PATH = '../input/birds21wi/birds/test'\n",
    "H5_TRAIN_PATH = '../input/224-compressed-train/birds21wi_train.h5'\n",
    "H5_VALID_PATH = '../input/224-compressed-valid/birds21wi_valid.h5'\n",
    "\n",
    "# k fold on training\n",
    "# Final CNN should just train on the full train set\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.RandomCrop(IMG_SIZE, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n",
    "        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "class BirdH5Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, in_file):\n",
    "        self.in_file = in_file\n",
    "        \n",
    "    def __len__(self):\n",
    "        with h5py.File(self.in_file, 'r') as file:\n",
    "            length = file['labels'].shape[0]\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.in_file, 'r') as file:\n",
    "            image = file['images'][idx]\n",
    "            label = file['labels'][idx]\n",
    "        return (torch.tensor(image), torch.tensor(label))\n",
    "        \n",
    "\n",
    "def get_bird_dataloader():\n",
    "    trainset = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    \n",
    "    testset = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    \n",
    "    classes = open(\"/kaggle/input/birds21wi/birds/names.txt\").read().strip().split(\"\\n\")\n",
    "    \n",
    "    # Backward mapping to original class ids (from folder names) and species name (from names.txt)\n",
    "    class_to_idx = trainset.class_to_idx\n",
    "    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n",
    "    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n",
    "    \n",
    "    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n",
    "\n",
    "def get_kfold_bird_dataset():\n",
    "    trainset = BirdH5Dataset(H5_TRAIN_PATH)\n",
    "    validset = BirdH5Dataset(H5_VALID_PATH)\n",
    "    \n",
    "    classes = open(\"/kaggle/input/birds21wi/birds/names.txt\").read().strip().split(\"\\n\")\n",
    "    \n",
    "    return {'train' : trainset, 'validation' : validset, 'classes' : classes}\n",
    "\n",
    "def get_kfold_bird_dataset_old():\n",
    "    trainset = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform_train)\n",
    "    validset = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform_test)\n",
    "    \n",
    "    classes = open(\"/kaggle/input/birds21wi/birds/names.txt\").read().strip().split(\"\\n\")\n",
    "    \n",
    "    # Backward mapping to original class ids (from folder names) and species name (from names.txt)\n",
    "    class_to_idx = trainset.class_to_idx\n",
    "    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n",
    "    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n",
    "    return {'train': trainset, 'validation' : validset, 'to_class': idx_to_class, 'to_name':idx_to_name}\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def split_train(trainset, validset):\n",
    "    np.random.seed(42)\n",
    "    validset_size = len(validset)\n",
    "    indices = list(range(validset_size))\n",
    "    split = int(np.floor(VALIDATION_PERC * validset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(indices[split:])\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(indices[:split])\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=4)\n",
    "    validloader = torch.utils.data.DataLoader(validset, batch_size=1, sampler=valid_sampler, num_workers=4)\n",
    "    \n",
    "    resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "    #print(resnet)\n",
    "    resnet.fc = nn.Linear(2048, 555)\n",
    "\n",
    "    #Higher: more penalty for large weights, less powerful model\n",
    "    #Lower: less penalty, more overfitting\n",
    "\n",
    "    #losses = train(resnet, trainloader, epochs=EPOCHS, lr=.01, print_every=10, checkpoint_path='./')\n",
    "    state = torch.load('../input/resnet50/checkpoint-7.pkl')\n",
    "    losses = train(resnet, trainloader, epochs=EPOCHS, schedule={0:.01, 5:.001, 10:.0001}, print_every=10, state=state, checkpoint_path='./')\n",
    "    #losses = train_validate(resnet, trainloader, validloader, epochs=EPOCHS, schedule={0:.01, 5:.001, 10:.0001}, checkpoint_path='./')\n",
    "    #train_accu = accuracy(resnet, trainloader)\n",
    "    valid_accu = accuracy(resnet, validloader)\n",
    "    #print(\"Training accuracy: %f\" % train_accu)\n",
    "    print(\"Validation accuracy: %f\" % valid_accu)\n",
    "    \n",
    "    \n",
    "def kfold_train(trainset, validset):\n",
    "    valid_results = {} # for kfold results\n",
    "    #train_results = {}\n",
    "    torch.manual_seed(42) # fix random seed\n",
    "    \n",
    "    kfold = KFold(n_splits=K_FOLDS, shuffle=True)\n",
    "    \n",
    "    validset_size = len(validset)\n",
    "    indices = list(range(validset_size))\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(indices)):\n",
    "        print('Fold', fold)\n",
    "        train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0)\n",
    "        validloader = torch.utils.data.DataLoader(validset, batch_size=1, sampler=valid_sampler, num_workers=0)\n",
    "        \n",
    "        resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        #print(resnet)\n",
    "        resnet.fc = nn.Linear(2048, 555)\n",
    "        \n",
    "        losses = train(resnet, trainloader, epochs=EPOCHS, schedule={0:.01, 6:.001}, print_every=10, checkpoint_path='./')\n",
    "        \n",
    "        torch.save(resnet.state_dict(), f'./model-fold-{fold}.pth')\n",
    "        \n",
    "        #train_accu = accuracy(resnet, trainloader)\n",
    "        valid_accu = accuracy(resnet, validloader)\n",
    "        #print('Training Accuracy for fold %d: %d %%' % (fold, 100.0 * train_accu))\n",
    "        print('Validation Accuracy for fold %d: %d %%' % (fold, 100.0 * valid_accu))\n",
    "        #train_results[fold] = 100 * train_accu\n",
    "        valid_results[fold] = 100 * valid_accu\n",
    "        \n",
    "    \n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {K_FOLDS} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    #print('train')\n",
    "    #sum = 0.0\n",
    "    #for key, value in train_results.items():\n",
    "    #    print(f'Fold {key}: {value} %')\n",
    "    #    sum += value\n",
    "    #print(f'Training Average: {sum/len(train_results.items())} %')  \n",
    "    #print('validation')\n",
    "    sum = 0.0\n",
    "    for key, value in valid_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Validation Average: {sum/len(valid_results.items())} %')\n",
    "    \n",
    "def train_validate(net, dataloader, validloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n",
    "          verbose=1, state=None, schedule={}, checkpoint_path=None):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "\n",
    "    # Load previous training state\n",
    "    if state:\n",
    "        net.load_state_dict(state['net'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "        losses = state['losses']\n",
    "\n",
    "    # Fast forward lr schedule through already trained epochs\n",
    "    for epoch in range(start_epoch):\n",
    "        if epoch in schedule:\n",
    "            print (\"Learning rate: %f\"% schedule[epoch])\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = schedule[epoch]\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        sum_loss = 0.0\n",
    "\n",
    "        # Update learning rate when scheduled\n",
    "        if epoch in schedule:\n",
    "            print (\"Learning rate: %f\"% schedule[epoch])\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = schedule[epoch]\n",
    "                \n",
    "        count = 0\n",
    "        for i, batch in enumerate(dataloader, 0):\n",
    "            count += 1\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # autograd magic, computes all the partial derivatives\n",
    "            optimizer.step() # takes a step in gradient direction\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            sum_loss += loss.item()\n",
    "        if checkpoint_path:\n",
    "            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
    "            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
    "        print('epoch', epoch)\n",
    "        print('loss', sum_loss / count)\n",
    "        sum_loss = 0.0\n",
    "        #train_accu = accuracy(net, dataloader)\n",
    "        valid_accu = accuracy(net, validloader)\n",
    "        #print(\"Training accuracy: %f\" % train_accu)\n",
    "        print(\"Validation accuracy: %f\" % valid_accu)\n",
    "        print()\n",
    "    return losses\n",
    "    \n",
    "def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n",
    "          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "\n",
    "    # Load previous training state\n",
    "    if state:\n",
    "        net.load_state_dict(state['net'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "        losses = state['losses']\n",
    "\n",
    "    # Fast forward lr schedule through already trained epochs\n",
    "    for epoch in range(start_epoch):\n",
    "        if epoch in schedule:\n",
    "            print (\"Learning rate: %f\"% schedule[epoch])\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = schedule[epoch]\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        sum_loss = 0.0\n",
    "\n",
    "        # Update learning rate when scheduled\n",
    "        if epoch in schedule:\n",
    "            print (\"Learning rate: %f\"% schedule[epoch])\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = schedule[epoch]\n",
    "\n",
    "        for i, batch in enumerate(dataloader, 0):\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # autograd magic, computes all the partial derivatives\n",
    "            optimizer.step() # takes a step in gradient direction\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            if i % print_every == print_every-1:    # print every 10 mini-batches\n",
    "                if verbose:\n",
    "                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n",
    "                sum_loss = 0.0\n",
    "        if checkpoint_path:\n",
    "            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
    "            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
    "    return losses\n",
    "\n",
    "def smooth(x, size):\n",
    "    return np.convolve(x, np.ones(size)/size, mode='valid')\n",
    "\n",
    "def predict(net, dataloader, ofname):\n",
    "    out = open(ofname, 'w')\n",
    "    out.write(\"path,class\\n\")\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader, 0):\n",
    "            if i%100 == 0:\n",
    "                print(i)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            fname, _ = dataloader.dataset.samples[i]\n",
    "            #out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n",
    "            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], predicted.item()))\n",
    "    out.close()\n",
    "\n",
    "def accuracy(net, dataloader):\n",
    "    print('Start accuracy tests')\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader, 0):\n",
    "            if i%100 == 0:\n",
    "                print(i)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct/total\n",
    "\n",
    "def write_accuracy(train_accu, valid_accu, output_filename):\n",
    "    out = open(output_filename, 'w')\n",
    "    out.write(\"Training accuracy: %f\\n\" % train_accu)\n",
    "    out.write(\"Validation accuracy: %f\" % valid_accu)\n",
    "    out.close()\n",
    "    \n",
    "def predict_given_state():\n",
    "    data = get_bird_dataloader()\n",
    "    resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "    resnet.fc = nn.Linear(2048, 555)\n",
    "    state = torch.load('../input/resnet50/checkpoint-7.pkl')\n",
    "    losses = train(resnet, data['train'], epochs=EPOCHS, schedule={0:.01, 5:.001, 10:.0001}, state=state, print_every=10, checkpoint_path='./')\n",
    "    predict(resnet, data['test'], \"preds.csv\")\n",
    "    \n",
    "    \n",
    "#data = get_bird_data()\n",
    "data = get_kfold_bird_dataset()\n",
    "split_train(trainset=data['train'], validset=data['validation'])\n",
    "predict_given_state()\n",
    "\n",
    "#data = get_bird_dataloader()\n",
    "#resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        #print(resnet)\n",
    "#resnet.fc = nn.Linear(2048, 555)\n",
    "#state = torch.load('../input/resnet50/checkpoint-5.pkl')\n",
    "#losses = train(resnet, data['train'], epochs=EPOCHS, schedule={0:.01, 5:.001, 10:.0001}, state=state, print_every=10, checkpoint_path='./')\n",
    "#predict(resnet, data['test'], \"preds.csv\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataloader = torch.utils.data.DataLoader(data['train'], batch_size=1, shuffle=False, num_workers=4)\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "imshow(images[0])\n",
    "print(labels[0].item(), data['classes'][labels[0].item()])\n",
    "\n",
    "\n",
    "file = h5py.File(H5_PATH, 'r')\n",
    "print(file[\"images\"].shape)\n",
    "print(file[\"labels\"].shape)\n",
    "im_torch = torch.tensor(file[\"images\"][0])\n",
    "lb = file['labels'][0]\n",
    "imshow(im_torch)\n",
    "classes = open(\"/kaggle/input/birds21wi/birds/names.txt\").read().strip().split(\"\\n\")\n",
    "print(classes[lb], lb)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#kfold_train(trainset=data['train'], validset=data['validation'])\n",
    "\n",
    "# Use pretrained resnet\n",
    "#resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "#resnet.fc = nn.Linear(512, 555)\n",
    "#if torch.cuda.is_available():\n",
    " #   print('resnet set to cuda')\n",
    "  #  resnet.cuda()\n",
    "#print('load state')\n",
    "#state = torch.load('../input/splittrainmodel/checkpoint-5.pkl', map_location=torch.device('cpu'))\n",
    "#resnet.load_state_dict(state['net'])\n",
    "#print('load state done')\n",
    "\n",
    "#losses = train(resnet, data['train'], epochs=EPOCHS, lr=.01, print_every=10, checkpoint_path='./')\n",
    "\n",
    "#dataiter = iter(data['test'])\n",
    "#images, labels = dataiter.next()\n",
    "#imshow(images[0])\n",
    "#print(labels[0].item(), data['to_name'][labels[0].item()])\n",
    "#outputs = resnet(images)\n",
    "#_, predicted = torch.max(outputs.data, 1)\n",
    "#print(data['to_name'][predicted[0].item()], predicted[0].item())\n",
    "\n",
    "#plt.plot(smooth(losses,50))\n",
    "\n",
    "#predict(resnet, data['validation'], \"validpreds.csv\")\n",
    "#train_accu = accuracy(resnet, data['train'])\n",
    "#valid_accu = accuracy(resnet, data['validation'])\n",
    "#print(\"Training accuracy: %f\" % train_accu)\n",
    "#print(\"Validation accuracy: %f\" % valid_accu)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 549.529703,
   "end_time": "2021-03-14T18:44:35.022573",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-14T18:35:25.492870",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3f4f5dc98bfa4a6da02686e702efbd03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4633ee7b1e1e45e2a51bce34a8fedbc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6528a7876d6148918cfd5e176a55ac3f",
       "placeholder": "​",
       "style": "IPY_MODEL_d1b2dd0d63bf4831869f16261de236f6",
       "value": "100%"
      }
     },
     "6528a7876d6148918cfd5e176a55ac3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83918627a885485b8a00458ec4f75b2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "86d7f312646e440ca042cb6129a68def": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae049ee0c6d04d068d5d09ff1b874621": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cdd699c0b5dd48ce9ee0255153ad48fe",
       "placeholder": "​",
       "style": "IPY_MODEL_f90e4e346516476cb605f46ebaeb5513",
       "value": " 97.8M/97.8M [00:00&lt;00:00, 158MB/s]"
      }
     },
     "c37a9489bb4b4cce9c8162dc961dbe21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4633ee7b1e1e45e2a51bce34a8fedbc0",
        "IPY_MODEL_c546764bbbbc4e028c9139489f685b8f",
        "IPY_MODEL_ae049ee0c6d04d068d5d09ff1b874621"
       ],
       "layout": "IPY_MODEL_83918627a885485b8a00458ec4f75b2d"
      }
     },
     "c546764bbbbc4e028c9139489f685b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_86d7f312646e440ca042cb6129a68def",
       "max": 102502400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3f4f5dc98bfa4a6da02686e702efbd03",
       "value": 102502400.0
      }
     },
     "cdd699c0b5dd48ce9ee0255153ad48fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1b2dd0d63bf4831869f16261de236f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f90e4e346516476cb605f46ebaeb5513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
